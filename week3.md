# Weekly Project Progress Report

## Week Ending: 10-01-2023

### Week theme: Nvidia HiFi-GAN sound waveform generation pipeline

---

## 1. Overview

This week we finished our text-to-speech model by creating a waveform generation pipeline that complements the spectrograms created through our already existing code. This pipeline was created based on the Nvidia [HiFi-GAN](https://arxiv.org/abs/2010.05646) pretrained model.

---

## 2. Accomplishments

We used NVIDIA's HiFiGAN vocoder model to generate the waveforms for our sound based on mel spectrograms generated through a previous model. We chose NVIDIA's HiFiGAN as a waveform generator for the following reasons:
* As its name indicates, the HiFiGAN model is a Generative Adversarial Network model. GANs are the best type of model achieved so far when it comes to generating audio from mel spectograms.
* We thought the audio quality when using the HiFiGAN was superior to any other option, as it sounded cleaner and less noisy.

There were some challenges that came with trying to use the HiFiGAN waveform generator, however, as the input for this model was not compatible with the mel spectogram that `Tacotron2` outputted. To solve this problem we chose to use NVIDIA's text preprocessing system, coupled with the `fastpitch` pretrained mel spectrogram generator model. Both of these models were compatible with the NVIDIA HiFiGAN model, so we were able to finish our Text-To-Speech pipeline by importing the necessary libraries and pretrained models like so:

```python
import torch
import torchaudio
# Load the FastPitch model for mel spectrogram generation
fastpitch, generator_train_setup = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_fastpitch')

#
hifigan, vocoder_train_setup, denoiser = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_hifigan')
tp = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_textprocessing_utils', cmudict_path="cmudict-0.7b", heteronyms_path="heteronyms")

# Since the mel spectrogram and waveform generation could be very intensive, we might want to use a GPU
device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
print(f'Using {device} for inference')


# Shift all our models to the GPU if we can
fastpitch.to(device)
hifigan.to(device)
denoiser.to(device)

# We import IPython to listen to audio right from the Notebook
import IPython

text = "Hello World! So nice to be talking, as I am a computer!"

# We use NVIDIA's text preprocessor to preprocess the text, the process is almost identical to Week 1
batches = tp.prepare_input_sequence([text], batch_size=1)

# We prepare some hyperparameters for the HifiGAN and the denoiser 
gen_kw = {'pace': 1.0,
          'speaker': 0,
          'pitch_tgt': None,
          'pitch_transform': None}
denoising_strength = 0.005

for batch in batches:
    with torch.no_grad():
        # We use fastpitch to generate a mel spectogram
        mel, mel_lens, *_ = fastpitch(batch['text'].to(device), **gen_kw)

        # Pass in the mel spectrogram generated by fastpitch to HifiGAN which returns the waveform
        audios = hifigan(mel).float()

        # Pass in the audio to the denoiser which returns the transformed audio
        audios = denoiser(audios.squeeze(1), denoising_strength)

        # Post-processing transformation to convert `audios` to a convenient shape 
        audios = audios.squeeze(1) * vocoder_train_setup['max_wav_value']
audio_numpy = audios[0].cpu().numpy()

# We use IPython to display audio in the notebook so we can listen to it
IPython.display.Audio(audio_numpy, rate=22050)
```

For more information refer to our [Google Colab Notebook](#7-google-colab-link)

---

## 3. Challenges and Solutions

Challenges encountered during the week and the solutions used to overcome them:
* We ran into some issues with the incompatibily of `Tacotron2` and the HiFiGAN. We solved this problem by finding a mel spetrogram generator model that was compatible with NVIDIA's HiFiGAN.

---

## 4. Upcoming Tasks

A list of tasks and deliverables that are projected for the upcoming week:
* Writing the Week4 Latex paper for the TTS project.
* Plugging together every part of the TTS pipeline, making ure the final code is both in the Colab and in the Latex paper.
---
## 5. Requests for Assistance

For now we do not need much assistance, although it would be good to have some clarification on what a Computer Science Latex paper should look like when it comes to format.

---

## 6. Additional Notes

There is no other information worth noting, but if it ever arises it will be shared with the Professor.

## 7. Google Colab link

Here is the [link to the Google Colab Notebook](https://colab.research.google.com/drive/1zQ8nwXlbIua2XEg9zxjAkoQnOgykd2EZ?usp=sharing)

â€”